<!--
  ðŸ‘‹ Hello! This is an ml5.js example made and shared with â¤ï¸.
  Learn more about the ml5.js project: https://ml5js.org/
  ml5.js license and Code of Conduct: https://github.com/ml5js/ml5-next-gen/blob/main/LICENSE.md
 
  This example demonstrates loading a Sign Language classifier through ml5.neuralNetwork with sequeceClassification Task.
-->

<html>
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>ml5.js Time Series Hand Gesture load model</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.4/p5.min.js"></script>
    <script src="../../dist/ml5.js"></script>
  </head>

  <body>
    <script src="sketch.js"></script>
    <div id="canvasDiv"></div>
    <p>
      This example loads a model that is trained with ASL hand gestures for
      Hello and Goodbye. <br />
      <br />

      Instructions: <br />
      1.) Use one hand to do a gesture in front of the camera <br />
      2.) Wait for the points to disappear or the prediction appears on
      screen<br />
      3.) To predict again, remove your hands in the frame and do the gesture
      again<br /><br />

      How to do gestures for Hello and Goodbye in ASL: <br />
      Hello:
      <a href="https://babysignlanguage.com/dictionary/hello/"
        >https://babysignlanguage.com/dictionary/hello/ </a
      ><br />
      Goodbye:
      <a href="https://babysignlanguage.com/dictionary/goodbye/"
        >https://babysignlanguage.com/dictionary/goodbye/ </a
      ><br />
    </p>
  </body>
</html>
